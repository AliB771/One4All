<<<<<<< HEAD

=======
# ðŸŸ¢ One4All: Modular Expert System with SLMs

**One4All** is a modular AI system that combines multiple **Specialized Language Models (SLMs)** trained on specific domains using **QLoRA**. Instead of relying on a single large LLM, One4All keeps a lightweight base LLM always loaded and dynamically loads LoRA weights for domain-specific experts. This design enables high performance with minimal hardware requirements.

---

## ðŸš€ How It Works (English)

1. **Question Routing**  
   When a question is asked, it first goes to the **Router**, a lightweight classifier model. The router analyzes the query and determines which domain-specific expert(s) should handle it.

2. **Expert Processing**  
   Experts are **SLMs trained on specialized datasets** (e.g., medical, technology, e-commerce). Once the router identifies the relevant domain, the question is forwarded to the corresponding expert. Each expert loads only its LoRA weights on the base model, minimizing memory usage.

3. **Why SLMs?**  
   - SLMs allow running domain-specific tasks efficiently on smaller hardware (e.g., a single GPU with 8â€“12GB VRAM).  
   - They reduce training and inference costs compared to a large monolithic LLM.  
   - Each expert can be independently updated without retraining the base model.

4. **Memory Efficiency**  
   Example:  
   - A base model (e.g., ParsBERT) with QLoRA LoRA weights for 3 experts may require **~12â€“16GB RAM per expert** loaded sequentially.  
   - A comparable LLM (7B+ parameters) may require **>40GB RAM** to run a single instance.  
   Using SLMs + LoRA reduces hardware requirements and enables modular scaling.

5. **Example Flow**
```text
Question: "Which smartphone has the best camera in 2025?"
  â†“
Router: Classifies as "Mobile/Technology"
  â†“
Expert: Mobile Expert (SLM trained on mobile reviews)
  â†“
Answer returned from expert
```

---

## ðŸ“Š Recommended SLMs for One4All

| Model Name           | Languages Supported | Domain Specialization       | QLoRA Memory Req |
|---------------------|------------------|----------------------------|----------------|
| ParsBERT            | Persian           | General / NLP tasks        | 4â€“6 GB         |
| mBERT               | Multi-language    | General                    | 6â€“8 GB         |
| CamemBERT            | French            | General                    | 4â€“6 GB         |
| Qwen3-SLM           | English, Multi    | Causal Language Modeling   | 8â€“12 GB        |
| SaadiBERT            | Persian           | Medical / Healthcare       | 4â€“6 GB         |

> One4All can dynamically load multiple SLM experts depending on the task.

---

## ðŸ”§ Technical Notes

- **Base model** always loaded in memory.  
- **LoRA adapters** applied for each expert separately.  
- Router is a **lightweight classification model** that routes queries efficiently.  
- Supports **multi-domain modular updates** without retraining the base LLM.  

**References:**  
- Hu et al., *LoRA: Low-Rank Adaptation of Large Language Models*, 2021  
- Qwen3 model papers and SLM studies in Persian and English NLP  

---

# ðŸŸ¢ One4All: Ø³ÛŒØ³ØªÙ… Ù…ØªØ®ØµØµ Ù…Ø§Ú˜ÙˆÙ„Ø§Ø± Ø¨Ø§ SLMÙ‡Ø§

**One4All** ÛŒÚ© Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù…Ø§Ú˜ÙˆÙ„Ø§Ø± Ø§Ø³Øª Ú©Ù‡ ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² **Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ ØªØ®ØµØµÛŒ (SLM)** Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² **QLoRA** Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒÚ© Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ Ø¨Ø²Ø±Ú¯ØŒ One4All Ù‡Ù…ÛŒØ´Ù‡ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø³Ø¨Ú© Ø±Ø§ Ù„ÙˆØ¯ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯ Ùˆ ÙÙ‚Ø· ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ LoRA Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù…ØªØ®ØµØµâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

---

## ðŸš€ Ù†Ø­ÙˆÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ (ÙØ§Ø±Ø³ÛŒ)

1. **Ù…Ø³ÛŒØ±Ø¯Ù‡ÛŒ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§**  
   ÙˆÙ‚ØªÛŒ Ø³ÙˆØ§Ù„ÛŒ Ù¾Ø±Ø³ÛŒØ¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ù‡ **Router** Ù…ÛŒâ€ŒØ±ÙˆØ¯. Ø§ÛŒÙ† Ù…Ø¯Ù„ Ø³Ø¨Ú©ØŒ Ø²Ù…ÛŒÙ†Ù‡â€ŒÛŒ Ø³ÙˆØ§Ù„ Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ø¯Ø§Ù… Ù…ØªØ®ØµØµ ÛŒØ§ Ù…ØªØ®ØµØµâ€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ø¢Ù† Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù†Ø¯.

2. **Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ù…ØªØ®ØµØµâ€ŒÙ‡Ø§**  
   Ù…ØªØ®ØµØµâ€ŒÙ‡Ø§ **SLMÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø¯Ø± Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ** Ù‡Ø³ØªÙ†Ø¯ (Ù…Ø«Ù„Ø§Ù‹ Ù¾Ø²Ø´Ú©ÛŒØŒ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒØŒ Ø®Ø±ÛŒØ¯). Ù¾Ø³ Ø§Ø² Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø­ÙˆØ²Ù‡ ØªÙˆØ³Ø· RouterØŒ Ø³ÙˆØ§Ù„ Ø¨Ù‡ Ù…ØªØ®ØµØµ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ ØªÙ†Ù‡Ø§ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ LoRA Ø¢Ù† Ù…ØªØ®ØµØµ Ø±ÙˆÛŒ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ØªØ§ Ø­Ø§ÙØ¸Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡ Ø´ÙˆØ¯.

3. **Ú†Ø±Ø§ SLMØŸ**  
   - SLMÙ‡Ø§ Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ø±Ù‡Ø§ÛŒ ØªØ®ØµØµÛŒ Ø±Ø§ Ø¨Ø§ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ú©Ù… (Ù…Ø«Ù„Ø§Ù‹ ÛŒÚ© GPU Ø¨Ø§ 8â€“12GB VRAM) Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.  
   - Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù†Ø³Ø¨Øª Ø¨Ù‡ LLMÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ú©Ù…ØªØ± Ø§Ø³Øª.  
   - Ù‡Ø± Ù…ØªØ®ØµØµ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…Ø³ØªÙ‚Ù„ Ù‚Ø§Ø¨Ù„ Ø¢Ù¾Ø¯ÛŒØª Ø§Ø³Øª Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡.

4. **Ú©Ø§Ø±Ø§ÛŒÛŒ Ø­Ø§ÙØ¸Ù‡**  
   Ù…Ø«Ø§Ù„:  
   - Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ (ParsBERT) Ø¨Ø§ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ LoRA Ø³Ù‡ Ù…ØªØ®ØµØµ: **~12â€“16GB RAM** Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…ØªØ®ØµØµ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù…ØªÙˆØ§Ù„ÛŒ Ú©Ø§ÙÛŒ Ø§Ø³Øª.  
   - ÛŒÚ© LLM Ø¨Ø²Ø±Ú¯ (7B+ Ù¾Ø§Ø±Ø§Ù…ØªØ±) Ù†ÛŒØ§Ø²Ù…Ù†Ø¯ **>40GB RAM** Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª.  
   Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ†ØŒ SLMÙ‡Ø§ + LoRA Ù†ÛŒØ§Ø² Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±ÛŒ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø¯Ù‡ Ùˆ Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø±Ø§ Ø¢Ø³Ø§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.

5. **Ù…Ø«Ø§Ù„ Ø¬Ø±ÛŒØ§Ù† Ù¾Ø±Ø³Ø´**
```text
Ø³ÙˆØ§Ù„: "Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯ÙˆØ±Ø¨ÛŒÙ† Ú¯ÙˆØ´ÛŒ Ø¯Ø± 2025 Ú©Ø¯Ø§Ù… Ø§Ø³ØªØŸ"
  â†“
Router: Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ "Ù…ÙˆØ¨Ø§ÛŒÙ„ / ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ"
  â†“
Expert: Ù…ØªØ®ØµØµ Ù…ÙˆØ¨Ø§ÛŒÙ„ (SLM Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡ Ø±ÙˆÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¨Ø§ÛŒÙ„)
  â†“
Ù¾Ø§Ø³Ø® Ø§Ø² Ù…ØªØ®ØµØµ Ø¨Ø±Ú¯Ø´Øª Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

---

## ðŸ“Š SLMÙ‡Ø§ÛŒ ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ One4All

| Ù†Ø§Ù… Ù…Ø¯Ù„             | Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ | Ø­ÙˆØ²Ù‡ ØªØ®ØµØµÛŒ                  | Ù†ÛŒØ§Ø² Ø­Ø§ÙØ¸Ù‡ QLoRA |
|--------------------|--------------------|-----------------------------|----------------|
| ParsBERT            | ÙØ§Ø±Ø³ÛŒ               | Ø¹Ù…ÙˆÙ…ÛŒ / NLP                | 4â€“6 GB         |
| mBERT               | Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†             | Ø¹Ù…ÙˆÙ…ÛŒ                       | 6â€“8 GB         |
| CamemBERT           | ÙØ±Ø§Ù†Ø³Ù‡              | Ø¹Ù…ÙˆÙ…ÛŒ                       | 4â€“6 GB         |
| Qwen3-SLM           | Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†    | Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø²Ø¨Ø§Ù† Ø³Ø¨Ø¨ÛŒ (Causal) | 8â€“12 GB        |
| SaadiBERT           | ÙØ§Ø±Ø³ÛŒ               | Ù¾Ø²Ø´Ú©ÛŒ / Ø³Ù„Ø§Ù…Øª               | 4â€“6 GB         |

> One4All Ø¨Ù‡ ØµÙˆØ±Øª Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ú†Ù†Ø¯ Ù…ØªØ®ØµØµ SLM Ø±Ø§ Ø¨Ø³ØªÙ‡ Ø¨Ù‡ Ù¾Ø±Ø³Ø´ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

---

## ðŸ”§ Ù†Ú©Ø§Øª ÙÙ†ÛŒ

- **Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡** Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.  
- **LoRA adapters** Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…ØªØ®ØµØµ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.  
- Router Ù…Ø¯Ù„ Ø³Ø¨Ú© Ùˆ Ú©Ø§Ø±Ø¢Ù…Ø¯ÛŒ Ø§Ø³Øª Ú©Ù‡ Ù¾Ø±Ø³Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø³ÛŒØ±Ø¯Ù‡ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.  
- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² **Ø¢Ù¾Ø¯ÛŒØª Ù…Ø§Ú˜ÙˆÙ„Ø§Ø± Ú†Ù†Ø¯ Ø­ÙˆØ²Ù‡â€ŒØ§ÛŒ** Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡.  

**Ù…Ø±Ø§Ø¬Ø¹:**  
- Hu Ùˆ Ù‡Ù…Ú©Ø§Ø±Ø§Ù†ØŒ *LoRA: Low-Rank Adaptation of Large Language Models*, 2021  
- Ù…Ù‚Ø§Ù„Ø§Øª Qwen3 Ùˆ Ù¾Ú˜ÙˆÙ‡Ø´â€ŒÙ‡Ø§ÛŒ SLM Ø¯Ø± Ø­ÙˆØ²Ù‡ NLP ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ  

---

âœ… **Status:** Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø§Ù†Ø¬Ø§Ù… ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø³Øª.

>>>>>>> 709e9bd (feat: update README to reflect One4All project details and functionality)
